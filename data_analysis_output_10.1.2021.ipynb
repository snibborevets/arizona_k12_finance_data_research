{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from io import StringIO\n",
    "from sklearn import preprocessing\n",
    "from pandas import ExcelWriter\n",
    "from datetime import datetime\n",
    " \n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import openpyxl\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# larger output display when printing\n",
    "pd.set_option('display.max_rows', 750, 'display.max_columns', 500)  # show all rows and cols when printing output to terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "# IN: (1) label for x-axis variables and (2) pdSeries of y and x values \n",
    "# OUT: plot of histrogram\n",
    "\n",
    "def plot_compute_r_squared(feature_list, y, x_list):\n",
    "    \n",
    "#     font = {'family' : 'monospace',\n",
    "#         'weight' : 'bold',\n",
    "#         'size'   : '18'}\n",
    "\n",
    "#     params = {\"ytick.color\" : \"w\",\n",
    "#               \"xtick.color\" : \"w\",\n",
    "#               \"axes.labelcolor\" : \"w\",\n",
    "#               \"axes.edgecolor\" : \"w\"}\n",
    "\n",
    "\n",
    "#     plt.rc('font', **font)\n",
    "#     plt.rcParams.update(params)\n",
    "    \n",
    "    \n",
    "    num_features = len(feature_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     # make scatter plots and r2 for each feature individually against y\n",
    "#     fig, axs = plt.subplots(num_features, 1, figsize=(6, num_features*8))\n",
    "\n",
    "\n",
    "\n",
    "    # create lists to store regression outputs\n",
    "    r2_list = []\n",
    "    p_value_list = []\n",
    "    correlation_sign = []\n",
    "    slope_list = []\n",
    "\n",
    "    \n",
    "    # for each feature (individually!)\n",
    "    for i in range(0, num_features):\n",
    "\n",
    "        # run regression\n",
    "        slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(x_list[i], y)\n",
    "\n",
    "        # populate lists with regression outputs, round to 6 decimals\n",
    "        r2_list.append(np.around(r_value*r_value,6))   # r-value is \"correlation coefficient\"...square it to get r-squared\n",
    "        p_value_list.append(np.around(p_value,6))\n",
    "        slope_list.append(np.around(p_value,6))\n",
    "\n",
    "        # determine whether correlation is positive or negative\n",
    "        if (r_value<0):\n",
    "            correlation_sign.append('negative')\n",
    "        elif (r_value>=0):\n",
    "            correlation_sign.append('positive')\n",
    "\n",
    "#         # make scatter plot for each feature against assessment scores \n",
    "#         axs[i].scatter(x_list[i], y, alpha=0.5)\n",
    "#         axs[i].set_xlabel(feature_list[i])\n",
    "#         axs[i].set_ylabel('adj_assessment_score')\n",
    "        \n",
    "        \n",
    "    x = make_r2_table(r2_list, p_value_list, feature_list, correlation_sign)   \n",
    "        \n",
    "        \n",
    "#     n_bins=50\n",
    "\n",
    "#     fig, axs = plt.subplots(num_features, 1, figsize=(8,num_features*10))\n",
    "\n",
    "    \n",
    "#     for i in range(0,num_features):\n",
    "#         axs[i].hist(x_list[i], bins=n_bins)\n",
    "#         axs[i].set_xlabel(feature_list[i])\n",
    "    \n",
    "    r2_df = pd.DataFrame(data=[r2_list, feature_list, correlation_sign]).T\n",
    "    r2_df.columns = ['r2___', 'feature______________________________', 'correlation']\n",
    "    r2_df.sort_values(by=['r2___'],ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    return(x, r2_list, p_value_list, correlation_sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "# IN: (1) r2 values (2) names of features (3) correlation sign \n",
    "# OUT: table with r2 values and correlation sign\n",
    "\n",
    "def make_r2_table(r2_list, p_value_list, feature_list, correlation_sign):\n",
    "\n",
    "    r2_df = pd.DataFrame(data=[feature_list, r2_list, p_value_list, correlation_sign]).T\n",
    "    r2_df.columns = ['feature______________________________', 'r2___', 'p-value__', 'correlation']\n",
    "    r2_df_sorted = r2_df.sort_values(by=['r2___'],ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return(r2_df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "# IN: (1) raw data (2) minimum sum of proficiency percentages and\n",
    "#         (3) methods for filling missing values ('method'). '1' = scale to 100%, '2' = fill with 2.5 avg score\n",
    "# OUT: plot of histrogram\n",
    "\n",
    "def calculate_adj_assessment_scores(all_data_raw, min_sum_proficiency_percentages, method):\n",
    "\n",
    "    # create cols related to assessment scores\n",
    "    adj_assessment_score_list = []\n",
    "\n",
    "    # make list to store sum of the prof teir percentages\n",
    "    sum_proficiency_percentages_list = []\n",
    "\n",
    "    # store rows to drop if thresholds are breached\n",
    "    assessment_rows_to_drop = []\n",
    "\n",
    "    adj_score_raw_list = []\n",
    "    sum_prof_pcts_list = []\n",
    "\n",
    "    # assign weights to each prof teir\n",
    "    prof_4_wgt = 4\n",
    "    prof_3_wgt = 3\n",
    "    prof_2_wgt = 2\n",
    "    prof_1_wgt = 1\n",
    "\n",
    "    # calculate weighted assessment score and sum of prof percentages for each row to populate new columns\n",
    "    for i in range(0,len(all_data_raw)):\n",
    "        a = all_data_raw.loc[i, 'Percent Proficiency Level 1']\n",
    "        b = all_data_raw.loc[i, 'Percent Proficiency Level 2']\n",
    "        c = all_data_raw.loc[i, 'Percent Proficiency Level 3']\n",
    "        d = all_data_raw.loc[i, 'Percent Proficiency Level 4']\n",
    "\n",
    "        adj_score_raw = ((prof_4_wgt*d + prof_3_wgt*c + prof_2_wgt*b + prof_1_wgt*a)/100)\n",
    "        if (adj_score_raw==1):\n",
    "            print(i)\n",
    "\n",
    "        # sum up percentages\n",
    "        sum_prof_pcts = float((a + b + c + d))\n",
    "\n",
    "        # append adj raw score and sum pcts to list\n",
    "        adj_score_raw_list.append(adj_score_raw)\n",
    "        sum_prof_pcts_list.append(sum_prof_pcts)\n",
    "\n",
    "        # if no test records, set adj_score to zero (to avoid dividing by zero)\n",
    "        if (sum_prof_pcts == 0): \n",
    "            adj_score = 0\n",
    "\n",
    "        # scale score so that total of pcts equals 100%\n",
    "        else:\n",
    "            scale_to_100_pct = float(100/sum_prof_pcts)\n",
    "\n",
    "            if method == 1:\n",
    "                adj_score = np.multiply(adj_score_raw, scale_to_100_pct)\n",
    "\n",
    "            elif method == 2:\n",
    "                # assume all tests not in percentage get average score with 2.5 weighting\n",
    "                adj_score = adj_score_raw + (2.5*(100-sum_prof_pcts))/100\n",
    "\n",
    "\n",
    "        # append adj score and sum of prof pcts to lists\n",
    "        adj_assessment_score_list.append(adj_score)\n",
    "        sum_proficiency_percentages_list.append(sum_prof_pcts)\n",
    "\n",
    "        # establish min adj assessment score (so that when force adj score to zero in loop below, it will be dropped)\n",
    "        min_adj_assessment_score = 0.1\n",
    "        \n",
    "        # determine which rows need to be dropped based on parameters above\n",
    "        if (adj_score < min_adj_assessment_score or sum_prof_pcts < min_sum_proficiency_percentages):\n",
    "            assessment_rows_to_drop.append(i)\n",
    "\n",
    "    # print the number of rows to drop\n",
    "    print('Total Rows: ' + str(len(adj_assessment_score_list)))\n",
    "    print('Assessment Score Outliers: ' + str(len(assessment_rows_to_drop)))\n",
    "\n",
    "    return (adj_assessment_score_list, assessment_rows_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "# IN: all raw data\n",
    "# OUT: clean dataframe with adjusted assessment scores and ids\n",
    "\n",
    "def make_assess_df(all_data_raw, adj_assessment_score_list):\n",
    "\n",
    "    # make lea name and type columns\n",
    "    lea_name = pd.DataFrame([all_data_raw.loc[:,'Charter_District_Name'].values]).T\n",
    "    lea_type = pd.DataFrame([all_data_raw.loc[:,'Type'].values]).T\n",
    "\n",
    "    # make year and ctds-year-key columns\n",
    "    year = pd.DataFrame([all_data_raw.loc[:,'Year'].values]).T\n",
    "    ctds_year_key = pd.DataFrame([all_data_raw.loc[:,'ctds_year_key'].values]).T\n",
    "\n",
    "    # make ctds_id column in string format\n",
    "    ctds_id_str = all_data_raw.loc[:, 'ctds_id_str']\n",
    "    ctds_id = ctds_id_str.copy()\n",
    "\n",
    "    for i in range(0, len(ctds_id_str)):\n",
    "        ctds_id[i] = ctds_id_str[i][1:]\n",
    "        \n",
    "    # make assessment score columns\n",
    "    prof_level_1 = all_data_raw.loc[:, 'Percent Proficiency Level 1']\n",
    "    prof_level_2 = all_data_raw.loc[:, 'Percent Proficiency Level 2']\n",
    "    prof_level_3 = all_data_raw.loc[:, 'Percent Proficiency Level 3']\n",
    "    prof_level_4 = all_data_raw.loc[:, 'Percent Proficiency Level 4']\n",
    "\n",
    "    adj_assessment_score = pd.DataFrame([adj_assessment_score_list]).T\n",
    "    \n",
    "    assess_df = pd.concat([lea_name, lea_type, year, ctds_year_key, ctds_id, prof_level_1, prof_level_2, prof_level_3, prof_level_4, adj_assessment_score], axis=1)\n",
    "    assess_df.columns=['lea_name', 'lea_type', 'year', 'ctds_year_key', 'ctds_id', 'proficiency_level_1', 'proficiency_level_2', 'proficiency_level_3', 'proficiency_level_4', 'adj_assessment_score']\n",
    "    \n",
    "    return(assess_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "# IN: raw analysis dataframe, assessment rows to drop, desired lea type, and outlier list in format: ['feature_name', min_val, max_val]\n",
    "# OUT: analysis dataframe with outlier raws and removed\n",
    "\n",
    "def remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list):\n",
    "\n",
    "    school_type_rows_remove = []\n",
    "    year_rows_remove = []\n",
    "\n",
    "    for i in range(0, len(analysis_df_raw)):\n",
    "\n",
    "        if analysis_df_raw.loc[i, 'lea_type'] != school_type:\n",
    "            if school_type != 'all':\n",
    "                school_type_rows_remove.append(i)\n",
    "\n",
    "        if analysis_df_raw.loc[i, 'year'] != year:\n",
    "            if year != 'all':\n",
    "                year_rows_remove.append(i)\n",
    "    \n",
    "    rows_to_remove = []\n",
    "\n",
    "    for i in range(0, len(outlier_list)):\n",
    "\n",
    "        for j in range(0, len(analysis_df_raw)):                                \n",
    "\n",
    "            if analysis_df_raw.loc[j, outlier_list[i][0]] < outlier_list[i][1]: \n",
    "                rows_to_remove.append(j)\n",
    "\n",
    "            elif analysis_df_raw.loc[j, outlier_list[i][0]] > outlier_list[i][2]:\n",
    "                rows_to_remove.append(j)\n",
    "\n",
    "                \n",
    "    outlier_rows_to_remove = np.unique(rows_to_remove + assessment_rows_to_drop + school_type_rows_remove + year_rows_remove)\n",
    "    \n",
    "    analysis_df = analysis_df_raw.drop(outlier_rows_to_remove).reset_index(drop=True)\n",
    "\n",
    "    return(analysis_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "# IN: (1) clean data for analysis, (2) name of y column, (3) list of x feature names\n",
    "# OUT: (1) clean y values (2) clean list of x's \n",
    "\n",
    "def make_x_and_y(analysis_df, y_col_name, feature_list):\n",
    "    # make table of x-values, features, and y for plotting\n",
    "    y = analysis_df.loc[:, y_col_name]\n",
    "\n",
    "    # feature_list = list(analysis_df.columns[65:])\n",
    "\n",
    "    num_features = len(feature_list)\n",
    "\n",
    "\n",
    "    x_list = []\n",
    "\n",
    "    for i in range(0, num_features):\n",
    "\n",
    "        x = analysis_df.loc[:, feature_list[i]].values\n",
    "\n",
    "        x_list.append(x)\n",
    "\n",
    "    return(x_list, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "# IN: (1) metric to be computed into quartiles in form of pd.Series, \n",
    "#     (2) df for analysis with outliers removed, (3) list of QUARTILE cutoff points\n",
    "# OUT: (1) df of cutoff points and (2) df with quartile column added\n",
    "\n",
    "def compute_quartiles(metric_series, analysis_df, quantile_list):\n",
    "\n",
    "    # add id cols to df\n",
    "    metric_df = analysis_df.copy()\n",
    "\n",
    "    # all col for metric data\n",
    "    metric_df = metric_df.assign(metric=metric_series)\n",
    "    \n",
    "    # all col for quartile\n",
    "    metric_df = metric_df.assign(cutoff_quartile=np.zeros(len(metric_df)))\n",
    "\n",
    "    quartile_cutoffs = metric_series.quantile(quantile_list)\n",
    "\n",
    "    \n",
    "    \n",
    "    for i in range(0,len(metric_df)):\n",
    "\n",
    "        if(metric_df.loc[i,'metric'] <= quartile_cutoffs.values[0]):\n",
    "            metric_df.loc[i,'cutoff_quartile'] = 1\n",
    "\n",
    "        elif((metric_df.loc[i,'metric'] > quartile_cutoffs.values[0]) & (metric_df.loc[i,'metric'] < quartile_cutoffs.values[1])):\n",
    "            metric_df.loc[i,'cutoff_quartile'] = 2\n",
    "\n",
    "        elif((metric_df.loc[i,'metric'] >= quartile_cutoffs.values[1]) & (metric_df.loc[i,'metric'] < quartile_cutoffs.values[2])):\n",
    "            metric_df.loc[i,'cutoff_quartile'] = 3\n",
    "\n",
    "        else:\n",
    "            metric_df.loc[i,'cutoff_quartile'] = 4\n",
    "\n",
    "    return(quartile_cutoffs, metric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "# IN: DataFrame after outliers removed, target features to analyse correlation, quantile info and targeted feature\n",
    "# OUT: R-squared values for targeted features ran in analysis, DataFrame of quantile chosen with cutoff points\n",
    "\n",
    "def run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name):\n",
    "\n",
    "    metric_series = analysis_df.loc[:, target_col_name]\n",
    "    quartile_cutoffs, metric_df = compute_quartiles(metric_series, analysis_df, quantile_list)\n",
    "\n",
    "    metric_df_raw = metric_df.copy()\n",
    "    \n",
    "    metric_df = metric_df[metric_df.loc[:, 'cutoff_quartile'] == target_quartile]\n",
    "\n",
    "    quartile_cutoffs_df = pd.DataFrame([quantile_list, quartile_cutoffs]).T\n",
    "    quartile_cutoffs_df.columns = ['quartile_pct_cutoff', 'quartile_value']\n",
    "\n",
    "\n",
    "    # make x and y lists\n",
    "    x_list, y = make_x_and_y(metric_df, y_col_name, feature_list)\n",
    "\n",
    "    \n",
    "    # run analysis and create tables and plots\n",
    "    quartiles_df, r2_list, p_value_list, correlation_sign = plot_compute_r_squared(feature_list, y, x_list)\n",
    "     \n",
    "    return(metric_df, metric_df_raw, quartiles_df, quartile_cutoffs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "# IN: All inputs used to run analysis given outlier params, year, quantile params, targeted feature, etc)\n",
    "# OUT: DataFrame of all assumptions used in analysis (outliers, target features, quantile, filters, etc)\n",
    "\n",
    "def make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw):\n",
    "\n",
    "    # combine all assumptions for output into excel tab\n",
    "    a = pd.Series(feature_list)\n",
    "    b = pd.Series(outlier_list)\n",
    "    c = pd.Series(y_col_name)\n",
    "    d = pd.Series(year)\n",
    "    e = pd.Series(school_type)\n",
    "    f = pd.Series(quantile_list)\n",
    "    g = pd.Series(target_quartile)\n",
    "    h = pd.Series(target_col_name)\n",
    "    i = pd.Series(len(metric_df_raw[metric_df_raw.loc[:, 'cutoff_quartile'] == target_quartile]))\n",
    "    \n",
    "    assumptions_list = pd.concat([a, b, c, d, e, f, g, h, i], axis=1).T\n",
    "\n",
    "    assumptions_list_names = ['features_analyzed', 'outlier_params', 'y_variable', 'year', 'school_type', 'quantile_values', 'target_quartile_num', 'target_col_name', 'samples (n = ']\n",
    "\n",
    "    assumptions_list.insert(0, 'fields', assumptions_list_names)\n",
    "    \n",
    "    return(assumptions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "# IN: Raw DataFrame and DataFrame removing outliers, DataFrame with length of target quartile (non-unique LEAs)\n",
    "# OUT: DataFrame with sample sizes of all relevent DataFrames, unique and non-unique\n",
    "\n",
    "def make_unique_tab(analysis_df_raw, analysis_df, metric_df):\n",
    "    \n",
    "    # combine all assumptions for output into excel tab\n",
    "    a = pd.Series(len(analysis_df_raw))\n",
    "    b = pd.Series(len(analysis_df))\n",
    "    c = pd.Series(len(np.unique(analysis_df.ctds_id)))\n",
    "    d = pd.Series(len(metric_df))\n",
    "    e = pd.Series(len(np.unique(metric_df['ctds_id'])))\n",
    "    f = pd.Series(len(analysis_df_raw[analysis_df_raw.lea_type == 'district']))\n",
    "    g = pd.Series(len(analysis_df_raw[analysis_df_raw.lea_type == 'charter']))\n",
    "\n",
    "    \n",
    "    unique_list = pd.concat([a, b, c, d, e, f, g], axis=1).T\n",
    "\n",
    "    unique_list.columns = ['n samples']\n",
    "    \n",
    "    unique_list_names = ['raw_dataset', 'after_filters_outliers', 'unique_lea_all_quartiles', 'length_target_quartile', 'unique_lea_target_quartile', 'districts_raw', 'charters_raw']\n",
    "\n",
    "    unique_list.insert(0, 'fields', unique_list_names)\n",
    "    \n",
    "    return(unique_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "# IN: DataFrame after outliers removed, 2018 to 2019 wage inflation rate for teachers\n",
    "# OUT: DataFrame with only 2018 and 2019 values with adjusted average teacher salary info\n",
    "\n",
    "def create_teacher_salary_analysis_df(analysis_df, inflation_rate):\n",
    "\n",
    "    # run analysis and data tables for excel export\n",
    "    analysis_df_teach_raw = analysis_df[analysis_df.avg_teacher_salary > 0].reset_index(drop=True)\n",
    "    data_2018 = analysis_df_teach_raw[analysis_df_teach_raw.year==2018]\n",
    "    data_2019 = analysis_df_teach_raw[analysis_df_teach_raw.year==2019]\n",
    "\n",
    "    data_2018 = data_2018.assign(avg_teacher_salary_infl_x = ((1 + inflation_rate) * data_2018.avg_teacher_salary))\n",
    "    data_2019 = data_2019.assign(avg_teacher_salary_infl_x = data_2019.avg_teacher_salary)\n",
    "\n",
    "    analysis_df_teach = pd.concat([data_2018, data_2019])\n",
    "\n",
    "    return(analysis_df_teach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import raw data\n",
    "import_path = './jupyter_data/'\n",
    "all_data_raw = pd.read_csv(import_path +'joined_data.csv')\n",
    "\n",
    "# import afr metrics and other ratios df's\n",
    "afr_data_df = pd.read_csv(import_path + 'afr_data_df.csv')\n",
    "ratios_df = pd.read_csv(import_path + 'ratios_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Assessment Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 2698\n",
      "Assessment Score Outliers: 274\n"
     ]
    }
   ],
   "source": [
    "# establish cut off for sum of proficiency percentages\n",
    "min_sum_proficiency_percentages = 90\n",
    "\n",
    "# '1' = scale to 100%, '2' = fill with 2.5 avg score\n",
    "method = 1\n",
    "\n",
    "# calculate adjusted assessment scores\n",
    "adj_assessment_score_list, assessment_rows_to_drop = calculate_adj_assessment_scores(all_data_raw, min_sum_proficiency_percentages, method)\n",
    "\n",
    "# make data frame with adjusted assessment score data\n",
    "assess_df = make_assess_df(all_data_raw, adj_assessment_score_list)\n",
    "\n",
    "# combine all data and fill nan and inf with zeroes\n",
    "analysis_df_raw = pd.concat([assess_df, afr_data_df, ratios_df], axis=1).replace([np.inf, -np.inf], np.nan).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# add column for teacher data, will be adjusted by inflation later\n",
    "analysis_df_raw = analysis_df_raw.assign(avg_teacher_salary_infl_x = analysis_df_raw.avg_teacher_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# old outlier_list = [\n",
    "#     ['total_students', 20, 1000000],\n",
    "#     ['total_teachers', 4, 1000000],\n",
    "#     ['exp_to_rev_ratio', 0.60, 1.40],\n",
    "#     ['students_per_teacher', 4, 35],\n",
    "#     ['other_6800_per_total_exp', 0, 1],\n",
    "#     ['purch_serv_6300_6400_6500_per_total_exp', 0, 0.65],\n",
    "#     ['supplies_6600_per_total_exp', 0, 0.25],\n",
    "#     ['pct_free_reduced', 0, 1]\n",
    "#     ]    \n",
    "\n",
    "# school_type = 'charter'   # 'charter', 'district', 'all'\n",
    "\n",
    "# feature_list = [\n",
    "#     'pct_free_reduced',\n",
    "#     'pct_white',\n",
    "#     'instruction_1000_per_total_exp',\n",
    "#     'salaries_6100_per_total_exp',\n",
    "#     'salary_benefits_instruction_1000_6100_6200_per_total_exp',\n",
    "#     'salary_benefits_instruction_1000_6100_6200_class_site_per_total_exp',\n",
    "#     'admin_expenses_all_per_total_exp',\n",
    "#     'students_per_teacher'\n",
    "#     ]\n",
    "\n",
    "# y_col_name = 'adj_assessment_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features to compute R-squared on\n",
    "feature_list = [\n",
    "    'pct_free_reduced',\n",
    "    'pct_non_white',\n",
    "    'pct_swd',\n",
    "    'instruction_1000_per_total_exp',\n",
    "    'salaries_6100_per_total_exp',\n",
    "    'salary_benefits_instruction_1000_6100_6200_per_total_exp',\n",
    "    'salary_benefits_instruction_1000_6100_6200_class_site_per_total_exp',\n",
    "    'admin_expenses_all_per_total_exp',\n",
    "    'instruction_1000_reg_sped_per_teacher',\n",
    "    'students_per_teacher',\n",
    "    'total_instruction_related_personnel_per_total_exp',\n",
    "    'building_related_expenses_per_total_exp',\n",
    "    'avg_teacher_salary_infl_x',\n",
    "    'total_instruction_related_personnel_per_student',\n",
    "    'salary_benefits_instruction_1000_6100_6200_class_site_per_student',\n",
    "    'total_students',\n",
    "    ]\n",
    "\n",
    "# outlier params\n",
    "outlier_list = [\n",
    "    ['total_students', 20, 1000000],\n",
    "    ['total_teachers', 4, 1000000],\n",
    "    ['exp_to_rev_ratio', 0.60, 1.40],\n",
    "    ['students_per_teacher', 4, 50],\n",
    "    ['other_6800_per_total_exp', 0, 10],\n",
    "    ['purch_serv_6300_6400_6500_per_total_exp', 0, 0.65],\n",
    "    ['supplies_6600_per_total_exp', 0, 0.25],\n",
    "    ['pct_free_reduced', 0, 1.05],\n",
    "    ['pct_non_white', 0, 1.05],\n",
    "    ['pct_swd', 0.01, 0.25],\n",
    "    ['instruction_1000_reg_sped_per_teacher', 10000.0, 120000.0],\n",
    "#     ['admin_expenses_all_per_total_exp', 0.05, 0.25],\n",
    "#     ['building_related_expenses_per_total_exp', 0.05, 0.25],\n",
    "#     ['salary_benefits_instruction_1000_6100_6200_class_site_per_total_exp', 0.2, 0.6],\n",
    "    ['total_instruction_related_personnel_per_total_exp', 0.15, 0.65],\n",
    "#     ['total_instruction_related_personnel_per_student', 2000, 7000],\n",
    "#     ['regular_to_sped_instructional_related_ratio', 0, 50]\n",
    "    ]\n",
    "\n",
    "# wage inflation rate for teacher salary (actual average salary increase was 8% from 2018 to 2019) \n",
    "inflation_rate = 0.05  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Scenarios for Excel Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## Sample Scenario X (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run analysis X\n",
    "\n",
    "# choose dependent variable for computing correlation\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'district'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [1, 1, 1]\n",
    "target_quartile = 1\n",
    "target_col_name = 'total_students'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_x, quartile_cutoffs_df_x = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_x = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_x = make_unique_tab(analysis_df_raw, analysis_df, metric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature______________________________</th>\n",
       "      <th>r2___</th>\n",
       "      <th>p-value__</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pct_non_white</td>\n",
       "      <td>0.362874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>total_instruction_related_personnel_per_total_exp</td>\n",
       "      <td>0.313179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>instruction_1000_per_total_exp</td>\n",
       "      <td>0.267815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>salary_benefits_instruction_1000_6100_6200_cla...</td>\n",
       "      <td>0.204995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>salaries_6100_per_total_exp</td>\n",
       "      <td>0.204470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>salary_benefits_instruction_1000_6100_6200_per...</td>\n",
       "      <td>0.202614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pct_free_reduced</td>\n",
       "      <td>0.122957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>instruction_1000_reg_sped_per_teacher</td>\n",
       "      <td>0.054096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>total_instruction_related_personnel_per_student</td>\n",
       "      <td>0.019993</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>total_students</td>\n",
       "      <td>0.019232</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>students_per_teacher</td>\n",
       "      <td>0.009521</td>\n",
       "      <td>0.007819</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>salary_benefits_instruction_1000_6100_6200_cla...</td>\n",
       "      <td>0.008352</td>\n",
       "      <td>0.012761</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>avg_teacher_salary_infl_x</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.023406</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>admin_expenses_all_per_total_exp</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.075020</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pct_swd</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.496505</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>building_related_expenses_per_total_exp</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.645594</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature______________________________     r2___ p-value__  \\\n",
       "0                                       pct_non_white  0.362874  0.000000   \n",
       "1   total_instruction_related_personnel_per_total_exp  0.313179  0.000000   \n",
       "2                      instruction_1000_per_total_exp  0.267815  0.000000   \n",
       "3   salary_benefits_instruction_1000_6100_6200_cla...  0.204995  0.000000   \n",
       "4                         salaries_6100_per_total_exp  0.204470  0.000000   \n",
       "5   salary_benefits_instruction_1000_6100_6200_per...  0.202614  0.000000   \n",
       "6                                    pct_free_reduced  0.122957  0.000000   \n",
       "7               instruction_1000_reg_sped_per_teacher  0.054096  0.000000   \n",
       "8     total_instruction_related_personnel_per_student  0.019993  0.000111   \n",
       "9                                      total_students  0.019232  0.000151   \n",
       "10                               students_per_teacher  0.009521  0.007819   \n",
       "11  salary_benefits_instruction_1000_6100_6200_cla...  0.008352  0.012761   \n",
       "12                          avg_teacher_salary_infl_x  0.006924  0.023406   \n",
       "13                   admin_expenses_all_per_total_exp  0.004277  0.075020   \n",
       "14                                            pct_swd  0.000625  0.496505   \n",
       "15            building_related_expenses_per_total_exp  0.000286  0.645594   \n",
       "\n",
       "   correlation  \n",
       "0     negative  \n",
       "1     positive  \n",
       "2     positive  \n",
       "3     positive  \n",
       "4     positive  \n",
       "5     positive  \n",
       "6     negative  \n",
       "7     positive  \n",
       "8     positive  \n",
       "9     positive  \n",
       "10    positive  \n",
       "11    positive  \n",
       "12    positive  \n",
       "13    positive  \n",
       "14    positive  \n",
       "15    positive  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quartiles_df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742\n"
     ]
    }
   ],
   "source": [
    "print(len(analysis_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Scenarios for Research Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## All LEAs, All Quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 1\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'all'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [1, 1, 1]\n",
    "target_quartile = 1\n",
    "target_col_name = 'pct_non_white'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_1, quartile_cutoffs_df_1 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_1 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_1 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_1_teach, quartile_cutoffs_df_1_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_1_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_1_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## District, All Quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 2\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'district'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [1, 1, 1]\n",
    "target_quartile = 1\n",
    "target_col_name = 'pct_non_white'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_2, quartile_cutoffs_df_2 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_2 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_2 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_2_teach, quartile_cutoffs_df_2_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_2_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_2_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Charters, All Quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 3\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'charter'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [1, 1, 1]\n",
    "target_quartile = 1\n",
    "target_col_name = 'pct_non_white'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_3, quartile_cutoffs_df_3 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_3 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_3 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_3_teach, quartile_cutoffs_df_3_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_3_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_3_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## District, Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 4\n",
    "\n",
    "# choose dependent variable for computing correlation\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'district'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 1\n",
    "target_col_name = 'pct_non_white'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_4, quartile_cutoffs_df_4 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_4 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_4 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_4_teach, quartile_cutoffs_df_4_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_4_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_4_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 5\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'district'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 2\n",
    "target_col_name = 'pct_non_white'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_5, quartile_cutoffs_df_5 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_5 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_5 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_5_teach, quartile_cutoffs_df_5_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_5_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_5_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 6\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'district'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 3\n",
    "target_col_name = 'pct_non_white'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_6, quartile_cutoffs_df_6 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_6 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_6 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_6_teach, quartile_cutoffs_df_6_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_6_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_6_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 7\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'district'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 4\n",
    "target_col_name = 'pct_non_white'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_7, quartile_cutoffs_df_7 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_7 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_7 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_7_teach, quartile_cutoffs_df_7_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_7_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_7_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## District, FRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 8\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'district'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 1\n",
    "target_col_name = 'pct_free_reduced'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_8, quartile_cutoffs_df_8 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_8 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_8 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_8_teach, quartile_cutoffs_df_8_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_8_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_8_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 9\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'district'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 2\n",
    "target_col_name = 'pct_free_reduced'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_9, quartile_cutoffs_df_9 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_9 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_9 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_9_teach, quartile_cutoffs_df_9_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_9_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_9_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 10\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'district'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 3\n",
    "target_col_name = 'pct_free_reduced'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_10, quartile_cutoffs_df_10 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_10 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_10 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_10_teach, quartile_cutoffs_df_10_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_10_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_10_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 11\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'district'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 4\n",
    "target_col_name = 'pct_free_reduced'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_11, quartile_cutoffs_df_11 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_11 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_11 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_11_teach, quartile_cutoffs_df_11_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_11_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_11_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## District, SWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 12\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'district'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 1\n",
    "target_col_name = 'pct_swd'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_12, quartile_cutoffs_df_12 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_12 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_12 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_12_teach, quartile_cutoffs_df_12_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_12_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_12_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 13\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'district'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 2\n",
    "target_col_name = 'pct_swd'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_13, quartile_cutoffs_df_13 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_13 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_13 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_13_teach, quartile_cutoffs_df_13_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_13_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_13_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 14\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'district'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 3\n",
    "target_col_name = 'pct_swd'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_14, quartile_cutoffs_df_14 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_14 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_14 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_14_teach, quartile_cutoffs_df_14_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_14_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_14_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 15\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'district'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 4\n",
    "target_col_name = 'pct_swd'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_15, quartile_cutoffs_df_15 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_15 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_15 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_15_teach, quartile_cutoffs_df_15_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_15_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_15_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Charter, Non-White"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 16\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'charter'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 1\n",
    "target_col_name = 'pct_non_white'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_16, quartile_cutoffs_df_16 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_16 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_16 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_16_teach, quartile_cutoffs_df_16_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_16_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_16_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 17\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'charter'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 2\n",
    "target_col_name = 'pct_non_white'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_17, quartile_cutoffs_df_17 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_17 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_17 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_17_teach, quartile_cutoffs_df_17_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_17_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_17_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 18\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'charter'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 3\n",
    "target_col_name = 'pct_non_white'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_18, quartile_cutoffs_df_18 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_18 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_18 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_18_teach, quartile_cutoffs_df_18_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_18_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_18_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 19\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'charter'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 4\n",
    "target_col_name = 'pct_non_white'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_19, quartile_cutoffs_df_19 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_19 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_19 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_19_teach, quartile_cutoffs_df_19_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_19_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_19_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Charter, FRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 20\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'charter'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 1\n",
    "target_col_name = 'pct_free_reduced'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_20, quartile_cutoffs_df_20 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_20 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_20 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_20_teach, quartile_cutoffs_df_20_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_20_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_20_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 21\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'charter'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 2\n",
    "target_col_name = 'pct_free_reduced'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_21, quartile_cutoffs_df_21 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_21 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_21 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_21_teach, quartile_cutoffs_df_21_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_21_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_21_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 22\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'charter'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 3\n",
    "target_col_name = 'pct_free_reduced'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_22, quartile_cutoffs_df_22 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_22 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_22 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_22_teach, quartile_cutoffs_df_22_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_22_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_22_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 23\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'charter'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 4\n",
    "target_col_name = 'pct_free_reduced'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_23, quartile_cutoffs_df_23 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_23 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_23 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_23_teach, quartile_cutoffs_df_23_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_23_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_23_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Charter, SWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 24\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'charter'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 1\n",
    "target_col_name = 'pct_swd'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_24, quartile_cutoffs_df_24 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_24 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_24 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_24_teach, quartile_cutoffs_df_24_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_24_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_24_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 25\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'charter'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 2\n",
    "target_col_name = 'pct_swd'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_25, quartile_cutoffs_df_25 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_25 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_25 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_25_teach, quartile_cutoffs_df_25_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_25_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_25_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 26\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'charter'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 3\n",
    "target_col_name = 'pct_swd'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_26, quartile_cutoffs_df_26 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_26 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_26 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_26_teach, quartile_cutoffs_df_26_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_26_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_26_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 27\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'charter'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 4\n",
    "target_col_name = 'pct_swd'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_27, quartile_cutoffs_df_27 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_27 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_27 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_27_teach, quartile_cutoffs_df_27_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_27_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_27_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## District, School Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 28\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'district'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 1\n",
    "target_col_name = 'total_students'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_28, quartile_cutoffs_df_28 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_28 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_28 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_28_teach, quartile_cutoffs_df_28_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_28_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_28_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 29\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'district'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 2\n",
    "target_col_name = 'total_students'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_29, quartile_cutoffs_df_29 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_29 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_29 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_29_teach, quartile_cutoffs_df_29_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_29_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_29_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 30\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'district'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 3\n",
    "target_col_name = 'total_students'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_30, quartile_cutoffs_df_30 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_30 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_30 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_30_teach, quartile_cutoffs_df_30_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_30_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_30_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 31\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'district'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 4\n",
    "target_col_name = 'total_students'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_31, quartile_cutoffs_df_31 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_31 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_31 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_31_teach, quartile_cutoffs_df_31_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_31_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_31_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Charter, School Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 32\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'charter'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 1\n",
    "target_col_name = 'total_students'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_32, quartile_cutoffs_df_32 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_32 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_32 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_32_teach, quartile_cutoffs_df_32_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_32_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_32_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 33\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'charter'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 2\n",
    "target_col_name = 'total_students'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_33, quartile_cutoffs_df_33 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_33 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_33 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_33_teach, quartile_cutoffs_df_33_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_33_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_33_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 34\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'charter'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 3\n",
    "target_col_name = 'total_students'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_34, quartile_cutoffs_df_34 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_34 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_34 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_34_teach, quartile_cutoffs_df_34_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_34_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_34_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# run analysis 35\n",
    "\n",
    "# dependent variable\n",
    "y_col_name = 'adj_assessment_score'\n",
    "\n",
    "year = 'all'   # 2015 to 2019, or 'all'\n",
    "school_type = 'charter'   # 'charter', 'district', 'all'\n",
    "\n",
    "# quartile slicing assumptions\n",
    "quantile_list = [0.25, 0.50, 0.75]\n",
    "target_quartile = 4\n",
    "target_col_name = 'total_students'\n",
    "\n",
    "# remove outliers\n",
    "analysis_df = remove_outliers(analysis_df_raw, assessment_rows_to_drop, school_type, year, outlier_list)\n",
    "\n",
    "# run analysis and data tables for excel export\n",
    "metric_df, metric_df_raw, quartiles_df_35, quartile_cutoffs_df_35 = run_analysis(analysis_df, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_35 = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_35 = make_unique_tab(analysis_df_raw, analysis_df, metric_df)\n",
    "\n",
    "# do same for teacher salary data, 2018 and 2019 only\n",
    "analysis_df_teach = create_teacher_salary_analysis_df(analysis_df, inflation_rate)\n",
    "metric_df_teach, metric_df_raw_teach, quartiles_df_35_teach, quartile_cutoffs_df_35_teach = run_analysis(analysis_df_teach, feature_list, y_col_name, quantile_list, target_quartile, target_col_name)\n",
    "assumptions_list_35_teach = make_assumptions_tab(feature_list, outlier_list, y_col_name, year, school_type, quantile_list, target_quartile, target_col_name, metric_df_raw)\n",
    "unique_list_35_teach = make_unique_tab(analysis_df_raw, analysis_df_teach, metric_df_teach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Data to Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create and Write Excel File\n",
    "\n",
    "export_path = './jupyter_data/'\n",
    "\n",
    "\n",
    "writer = pd.ExcelWriter(export_path + 'test_23.xlsx', engine='xlsxwriter')\n",
    "    \n",
    "\n",
    "analysis_df_raw.to_excel(writer, sheet_name='analysis_df_raw')\n",
    "metric_df_raw.to_excel(writer, sheet_name='remove_outliers')\n",
    "\n",
    "\n",
    "assumptions_list_1.to_excel(writer, sheet_name='slicing_assumptions_1')\n",
    "quartiles_df_1.to_excel(writer, sheet_name='quartiles_analysis_1')\n",
    "quartile_cutoffs_df_1.to_excel(writer, sheet_name='quartile_cutoffs_1')\n",
    "unique_list_1.to_excel(writer, sheet_name='unique_1')\n",
    "quartiles_df_1_teach.to_excel(writer, sheet_name='quartiles_analysis_1_teach')\n",
    "quartile_cutoffs_df_1_teach.to_excel(writer, sheet_name='quartile_cutoffs_1_teach')\n",
    "unique_list_1_teach.to_excel(writer, sheet_name='unique_1_teach')\n",
    "\n",
    "assumptions_list_2.to_excel(writer, sheet_name='slicing_assumptions_2')\n",
    "quartiles_df_2.to_excel(writer, sheet_name='quartiles_analysis_2')\n",
    "quartile_cutoffs_df_2.to_excel(writer, sheet_name='quartile_cutoffs_2')\n",
    "unique_list_2.to_excel(writer, sheet_name='unique_2')\n",
    "quartiles_df_2_teach.to_excel(writer, sheet_name='quartiles_analysis_2_teach')\n",
    "quartile_cutoffs_df_2_teach.to_excel(writer, sheet_name='quartile_cutoffs_2_teach')\n",
    "unique_list_2_teach.to_excel(writer, sheet_name='unique_2_teach')\n",
    "\n",
    "assumptions_list_3.to_excel(writer, sheet_name='slicing_assumptions_3')\n",
    "quartiles_df_3.to_excel(writer, sheet_name='quartiles_analysis_3')\n",
    "quartile_cutoffs_df_3.to_excel(writer, sheet_name='quartile_cutoffs_3')\n",
    "unique_list_3.to_excel(writer, sheet_name='unique_3')\n",
    "quartiles_df_3_teach.to_excel(writer, sheet_name='quartiles_analysis_3_teach')\n",
    "quartile_cutoffs_df_3_teach.to_excel(writer, sheet_name='quartile_cutoffs_3_teach')\n",
    "unique_list_3_teach.to_excel(writer, sheet_name='unique_3_teach')\n",
    "\n",
    "assumptions_list_4.to_excel(writer, sheet_name='slicing_assumptions_4')\n",
    "quartiles_df_4.to_excel(writer, sheet_name='quartiles_analysis_4')\n",
    "quartile_cutoffs_df_4.to_excel(writer, sheet_name='quartile_cutoffs_4')\n",
    "unique_list_4.to_excel(writer, sheet_name='unique_4')\n",
    "quartiles_df_4_teach.to_excel(writer, sheet_name='quartiles_analysis_4_teach')\n",
    "quartile_cutoffs_df_4_teach.to_excel(writer, sheet_name='quartile_cutoffs_4_teach')\n",
    "unique_list_4_teach.to_excel(writer, sheet_name='unique_4_teach')\n",
    "\n",
    "assumptions_list_5.to_excel(writer, sheet_name='slicing_assumptions_5')\n",
    "quartiles_df_5.to_excel(writer, sheet_name='quartiles_analysis_5')\n",
    "quartile_cutoffs_df_5.to_excel(writer, sheet_name='quartile_cutoffs_5')\n",
    "unique_list_5.to_excel(writer, sheet_name='unique_5')\n",
    "quartiles_df_5_teach.to_excel(writer, sheet_name='quartiles_analysis_5_teach')\n",
    "quartile_cutoffs_df_5_teach.to_excel(writer, sheet_name='quartile_cutoffs_5_teach')\n",
    "unique_list_5_teach.to_excel(writer, sheet_name='unique_5_teach')\n",
    "\n",
    "assumptions_list_6.to_excel(writer, sheet_name='slicing_assumptions_6')\n",
    "quartiles_df_6.to_excel(writer, sheet_name='quartiles_analysis_6')\n",
    "quartile_cutoffs_df_6.to_excel(writer, sheet_name='quartile_cutoffs_6')\n",
    "unique_list_6.to_excel(writer, sheet_name='unique_6')\n",
    "quartiles_df_6_teach.to_excel(writer, sheet_name='quartiles_analysis_6_teach')\n",
    "quartile_cutoffs_df_6_teach.to_excel(writer, sheet_name='quartile_cutoffs_6_teach')\n",
    "unique_list_6_teach.to_excel(writer, sheet_name='unique_6_teach')\n",
    "\n",
    "assumptions_list_7.to_excel(writer, sheet_name='slicing_assumptions_7')\n",
    "quartiles_df_7.to_excel(writer, sheet_name='quartiles_analysis_7')\n",
    "quartile_cutoffs_df_7.to_excel(writer, sheet_name='quartile_cutoffs_7')\n",
    "unique_list_7.to_excel(writer, sheet_name='unique_7')\n",
    "quartiles_df_7_teach.to_excel(writer, sheet_name='quartiles_analysis_7_teach')\n",
    "quartile_cutoffs_df_7_teach.to_excel(writer, sheet_name='quartile_cutoffs_7_teach')\n",
    "unique_list_7_teach.to_excel(writer, sheet_name='unique_7_teach')\n",
    "\n",
    "assumptions_list_8.to_excel(writer, sheet_name='slicing_assumptions_8')\n",
    "quartiles_df_8.to_excel(writer, sheet_name='quartiles_analysis_8')\n",
    "quartile_cutoffs_df_8.to_excel(writer, sheet_name='quartile_cutoffs_8')\n",
    "unique_list_8.to_excel(writer, sheet_name='unique_8')\n",
    "quartiles_df_8_teach.to_excel(writer, sheet_name='quartiles_analysis_8_teach')\n",
    "quartile_cutoffs_df_8_teach.to_excel(writer, sheet_name='quartile_cutoffs_8_teach')\n",
    "unique_list_8_teach.to_excel(writer, sheet_name='unique_8_teach')\n",
    "\n",
    "assumptions_list_9.to_excel(writer, sheet_name='slicing_assumptions_9')\n",
    "quartiles_df_9.to_excel(writer, sheet_name='quartiles_analysis_9')\n",
    "quartile_cutoffs_df_9.to_excel(writer, sheet_name='quartile_cutoffs_9')\n",
    "unique_list_9.to_excel(writer, sheet_name='unique_9')\n",
    "quartiles_df_9_teach.to_excel(writer, sheet_name='quartiles_analysis_9_teach')\n",
    "quartile_cutoffs_df_9_teach.to_excel(writer, sheet_name='quartile_cutoffs_9_teach')\n",
    "unique_list_9_teach.to_excel(writer, sheet_name='unique_9_teach')\n",
    "\n",
    "assumptions_list_10.to_excel(writer, sheet_name='slicing_assumptions_10')\n",
    "quartiles_df_10.to_excel(writer, sheet_name='quartiles_analysis_10')\n",
    "quartile_cutoffs_df_10.to_excel(writer, sheet_name='quartile_cutoffs_10')\n",
    "unique_list_10.to_excel(writer, sheet_name='unique_10')\n",
    "quartiles_df_10_teach.to_excel(writer, sheet_name='quartiles_analysis_10_teach')\n",
    "quartile_cutoffs_df_10_teach.to_excel(writer, sheet_name='quartile_cutoffs_10_teach')\n",
    "unique_list_10_teach.to_excel(writer, sheet_name='unique_10_teach')\n",
    "\n",
    "assumptions_list_11.to_excel(writer, sheet_name='slicing_assumptions_11')\n",
    "quartiles_df_11.to_excel(writer, sheet_name='quartiles_analysis_11')\n",
    "quartile_cutoffs_df_11.to_excel(writer, sheet_name='quartile_cutoffs_11')\n",
    "unique_list_11.to_excel(writer, sheet_name='unique_11')\n",
    "quartiles_df_11_teach.to_excel(writer, sheet_name='quartiles_analysis_11_teach')\n",
    "quartile_cutoffs_df_11_teach.to_excel(writer, sheet_name='quartile_cutoffs_11_teach')\n",
    "unique_list_11_teach.to_excel(writer, sheet_name='unique_11_teach')\n",
    "\n",
    "assumptions_list_12.to_excel(writer, sheet_name='slicing_assumptions_12')\n",
    "quartiles_df_12.to_excel(writer, sheet_name='quartiles_analysis_12')\n",
    "quartile_cutoffs_df_12.to_excel(writer, sheet_name='quartile_cutoffs_12')\n",
    "unique_list_12.to_excel(writer, sheet_name='unique_12')\n",
    "quartiles_df_12_teach.to_excel(writer, sheet_name='quartiles_analysis_12_teach')\n",
    "quartile_cutoffs_df_12_teach.to_excel(writer, sheet_name='quartile_cutoffs_12_teach')\n",
    "unique_list_12_teach.to_excel(writer, sheet_name='unique_12_teach')\n",
    "\n",
    "assumptions_list_13.to_excel(writer, sheet_name='slicing_assumptions_13')\n",
    "quartiles_df_13.to_excel(writer, sheet_name='quartiles_analysis_13')\n",
    "quartile_cutoffs_df_13.to_excel(writer, sheet_name='quartile_cutoffs_13')\n",
    "unique_list_13.to_excel(writer, sheet_name='unique_13')\n",
    "quartiles_df_13_teach.to_excel(writer, sheet_name='quartiles_analysis_13_teach')\n",
    "quartile_cutoffs_df_13_teach.to_excel(writer, sheet_name='quartile_cutoffs_13_teach')\n",
    "unique_list_13_teach.to_excel(writer, sheet_name='unique_13_teach')\n",
    "\n",
    "assumptions_list_14.to_excel(writer, sheet_name='slicing_assumptions_14')\n",
    "quartiles_df_14.to_excel(writer, sheet_name='quartiles_analysis_14')\n",
    "quartile_cutoffs_df_14.to_excel(writer, sheet_name='quartile_cutoffs_14')\n",
    "unique_list_14.to_excel(writer, sheet_name='unique_14')\n",
    "quartiles_df_14_teach.to_excel(writer, sheet_name='quartiles_analysis_14_teach')\n",
    "quartile_cutoffs_df_14_teach.to_excel(writer, sheet_name='quartile_cutoffs_14_teach')\n",
    "unique_list_14_teach.to_excel(writer, sheet_name='unique_14_teach')\n",
    "\n",
    "assumptions_list_15.to_excel(writer, sheet_name='slicing_assumptions_15')\n",
    "quartiles_df_15.to_excel(writer, sheet_name='quartiles_analysis_15')\n",
    "quartile_cutoffs_df_15.to_excel(writer, sheet_name='quartile_cutoffs_15')\n",
    "unique_list_15.to_excel(writer, sheet_name='unique_15')\n",
    "quartiles_df_15_teach.to_excel(writer, sheet_name='quartiles_analysis_15_teach')\n",
    "quartile_cutoffs_df_15_teach.to_excel(writer, sheet_name='quartile_cutoffs_15_teach')\n",
    "unique_list_15_teach.to_excel(writer, sheet_name='unique_15_teach')\n",
    "\n",
    "assumptions_list_16.to_excel(writer, sheet_name='slicing_assumptions_16')\n",
    "quartiles_df_16.to_excel(writer, sheet_name='quartiles_analysis_16')\n",
    "quartile_cutoffs_df_16.to_excel(writer, sheet_name='quartile_cutoffs_16')\n",
    "unique_list_16.to_excel(writer, sheet_name='unique_16')\n",
    "quartiles_df_16_teach.to_excel(writer, sheet_name='quartiles_analysis_16_teach')\n",
    "quartile_cutoffs_df_16_teach.to_excel(writer, sheet_name='quartile_cutoffs_16_teach')\n",
    "unique_list_16_teach.to_excel(writer, sheet_name='unique_16_teach')\n",
    "\n",
    "assumptions_list_17.to_excel(writer, sheet_name='slicing_assumptions_17')\n",
    "quartiles_df_17.to_excel(writer, sheet_name='quartiles_analysis_17')\n",
    "quartile_cutoffs_df_17.to_excel(writer, sheet_name='quartile_cutoffs_17')\n",
    "unique_list_17.to_excel(writer, sheet_name='unique_17')\n",
    "quartiles_df_17_teach.to_excel(writer, sheet_name='quartiles_analysis_17_teach')\n",
    "quartile_cutoffs_df_17_teach.to_excel(writer, sheet_name='quartile_cutoffs_17_teach')\n",
    "unique_list_17_teach.to_excel(writer, sheet_name='unique_17_teach')\n",
    "\n",
    "assumptions_list_18.to_excel(writer, sheet_name='slicing_assumptions_18')\n",
    "quartiles_df_18.to_excel(writer, sheet_name='quartiles_analysis_18')\n",
    "quartile_cutoffs_df_18.to_excel(writer, sheet_name='quartile_cutoffs_18')\n",
    "unique_list_18.to_excel(writer, sheet_name='unique_18')\n",
    "quartiles_df_18_teach.to_excel(writer, sheet_name='quartiles_analysis_18_teach')\n",
    "quartile_cutoffs_df_18_teach.to_excel(writer, sheet_name='quartile_cutoffs_18_teach')\n",
    "unique_list_18_teach.to_excel(writer, sheet_name='unique_18_teach')\n",
    "\n",
    "assumptions_list_19.to_excel(writer, sheet_name='slicing_assumptions_19')\n",
    "quartiles_df_19.to_excel(writer, sheet_name='quartiles_analysis_19')\n",
    "quartile_cutoffs_df_19.to_excel(writer, sheet_name='quartile_cutoffs_19')\n",
    "unique_list_19.to_excel(writer, sheet_name='unique_19')\n",
    "quartiles_df_19_teach.to_excel(writer, sheet_name='quartiles_analysis_19_teach')\n",
    "quartile_cutoffs_df_19_teach.to_excel(writer, sheet_name='quartile_cutoffs_19_teach')\n",
    "unique_list_19_teach.to_excel(writer, sheet_name='unique_19_teach')\n",
    "\n",
    "assumptions_list_20.to_excel(writer, sheet_name='slicing_assumptions_20')\n",
    "quartiles_df_20.to_excel(writer, sheet_name='quartiles_analysis_20')\n",
    "quartile_cutoffs_df_20.to_excel(writer, sheet_name='quartile_cutoffs_20')\n",
    "unique_list_20.to_excel(writer, sheet_name='unique_20')\n",
    "quartiles_df_20_teach.to_excel(writer, sheet_name='quartiles_analysis_20_teach')\n",
    "quartile_cutoffs_df_20_teach.to_excel(writer, sheet_name='quartile_cutoffs_20_teach')\n",
    "unique_list_20_teach.to_excel(writer, sheet_name='unique_20_teach')\n",
    "\n",
    "assumptions_list_21.to_excel(writer, sheet_name='slicing_assumptions_21')\n",
    "quartiles_df_21.to_excel(writer, sheet_name='quartiles_analysis_21')\n",
    "quartile_cutoffs_df_21.to_excel(writer, sheet_name='quartile_cutoffs_21')\n",
    "unique_list_21.to_excel(writer, sheet_name='unique_21')\n",
    "quartiles_df_21_teach.to_excel(writer, sheet_name='quartiles_analysis_21_teach')\n",
    "quartile_cutoffs_df_21_teach.to_excel(writer, sheet_name='quartile_cutoffs_21_teach')\n",
    "unique_list_21_teach.to_excel(writer, sheet_name='unique_21_teach')\n",
    "\n",
    "assumptions_list_22.to_excel(writer, sheet_name='slicing_assumptions_22')\n",
    "quartiles_df_22.to_excel(writer, sheet_name='quartiles_analysis_22')\n",
    "quartile_cutoffs_df_22.to_excel(writer, sheet_name='quartile_cutoffs_22')\n",
    "unique_list_22.to_excel(writer, sheet_name='unique_22')\n",
    "quartiles_df_22_teach.to_excel(writer, sheet_name='quartiles_analysis_22_teach')\n",
    "quartile_cutoffs_df_22_teach.to_excel(writer, sheet_name='quartile_cutoffs_22_teach')\n",
    "unique_list_22_teach.to_excel(writer, sheet_name='unique_22_teach')\n",
    "\n",
    "assumptions_list_23.to_excel(writer, sheet_name='slicing_assumptions_23')\n",
    "quartiles_df_23.to_excel(writer, sheet_name='quartiles_analysis_23')\n",
    "quartile_cutoffs_df_23.to_excel(writer, sheet_name='quartile_cutoffs_23')\n",
    "unique_list_23.to_excel(writer, sheet_name='unique_23')\n",
    "quartiles_df_23_teach.to_excel(writer, sheet_name='quartiles_analysis_23_teach')\n",
    "quartile_cutoffs_df_23_teach.to_excel(writer, sheet_name='quartile_cutoffs_23_teach')\n",
    "unique_list_23_teach.to_excel(writer, sheet_name='unique_23_teach')\n",
    "\n",
    "assumptions_list_24.to_excel(writer, sheet_name='slicing_assumptions_24')\n",
    "quartiles_df_24.to_excel(writer, sheet_name='quartiles_analysis_24')\n",
    "quartile_cutoffs_df_24.to_excel(writer, sheet_name='quartile_cutoffs_24')\n",
    "unique_list_24.to_excel(writer, sheet_name='unique_24')\n",
    "quartiles_df_24_teach.to_excel(writer, sheet_name='quartiles_analysis_24_teach')\n",
    "quartile_cutoffs_df_24_teach.to_excel(writer, sheet_name='quartile_cutoffs_24_teach')\n",
    "unique_list_24_teach.to_excel(writer, sheet_name='unique_24_teach')\n",
    "\n",
    "assumptions_list_25.to_excel(writer, sheet_name='slicing_assumptions_25')\n",
    "quartiles_df_25.to_excel(writer, sheet_name='quartiles_analysis_25')\n",
    "quartile_cutoffs_df_25.to_excel(writer, sheet_name='quartile_cutoffs_25')\n",
    "unique_list_25.to_excel(writer, sheet_name='unique_25')\n",
    "quartiles_df_25_teach.to_excel(writer, sheet_name='quartiles_analysis_25_teach')\n",
    "quartile_cutoffs_df_25_teach.to_excel(writer, sheet_name='quartile_cutoffs_25_teach')\n",
    "unique_list_25_teach.to_excel(writer, sheet_name='unique_25_teach')\n",
    "\n",
    "assumptions_list_26.to_excel(writer, sheet_name='slicing_assumptions_26')\n",
    "quartiles_df_26.to_excel(writer, sheet_name='quartiles_analysis_26')\n",
    "quartile_cutoffs_df_26.to_excel(writer, sheet_name='quartile_cutoffs_26')\n",
    "unique_list_26.to_excel(writer, sheet_name='unique_26')\n",
    "quartiles_df_26_teach.to_excel(writer, sheet_name='quartiles_analysis_26_teach')\n",
    "quartile_cutoffs_df_26_teach.to_excel(writer, sheet_name='quartile_cutoffs_26_teach')\n",
    "unique_list_26_teach.to_excel(writer, sheet_name='unique_26_teach')\n",
    "\n",
    "assumptions_list_27.to_excel(writer, sheet_name='slicing_assumptions_27')\n",
    "quartiles_df_27.to_excel(writer, sheet_name='quartiles_analysis_27')\n",
    "quartile_cutoffs_df_27.to_excel(writer, sheet_name='quartile_cutoffs_27')\n",
    "unique_list_27.to_excel(writer, sheet_name='unique_27')\n",
    "quartiles_df_27_teach.to_excel(writer, sheet_name='quartiles_analysis_27_teach')\n",
    "quartile_cutoffs_df_27_teach.to_excel(writer, sheet_name='quartile_cutoffs_27_teach')\n",
    "unique_list_27_teach.to_excel(writer, sheet_name='unique_27_teach')\n",
    "\n",
    "assumptions_list_28.to_excel(writer, sheet_name='slicing_assumptions_28')\n",
    "quartiles_df_28.to_excel(writer, sheet_name='quartiles_analysis_28')\n",
    "quartile_cutoffs_df_28.to_excel(writer, sheet_name='quartile_cutoffs_28')\n",
    "unique_list_28.to_excel(writer, sheet_name='unique_28')\n",
    "quartiles_df_28_teach.to_excel(writer, sheet_name='quartiles_analysis_28_teach')\n",
    "quartile_cutoffs_df_28_teach.to_excel(writer, sheet_name='quartile_cutoffs_28_teach')\n",
    "unique_list_28_teach.to_excel(writer, sheet_name='unique_28_teach')\n",
    "\n",
    "assumptions_list_29.to_excel(writer, sheet_name='slicing_assumptions_29')\n",
    "quartiles_df_29.to_excel(writer, sheet_name='quartiles_analysis_29')\n",
    "quartile_cutoffs_df_29.to_excel(writer, sheet_name='quartile_cutoffs_29')\n",
    "unique_list_29.to_excel(writer, sheet_name='unique_29')\n",
    "quartiles_df_29_teach.to_excel(writer, sheet_name='quartiles_analysis_29_teach')\n",
    "quartile_cutoffs_df_29_teach.to_excel(writer, sheet_name='quartile_cutoffs_29_teach')\n",
    "unique_list_29_teach.to_excel(writer, sheet_name='unique_29_teach')\n",
    "\n",
    "assumptions_list_30.to_excel(writer, sheet_name='slicing_assumptions_30')\n",
    "quartiles_df_30.to_excel(writer, sheet_name='quartiles_analysis_30')\n",
    "quartile_cutoffs_df_30.to_excel(writer, sheet_name='quartile_cutoffs_30')\n",
    "unique_list_30.to_excel(writer, sheet_name='unique_30')\n",
    "quartiles_df_30_teach.to_excel(writer, sheet_name='quartiles_analysis_30_teach')\n",
    "quartile_cutoffs_df_30_teach.to_excel(writer, sheet_name='quartile_cutoffs_30_teach')\n",
    "unique_list_30_teach.to_excel(writer, sheet_name='unique_30_teach')\n",
    "\n",
    "assumptions_list_31.to_excel(writer, sheet_name='slicing_assumptions_31')\n",
    "quartiles_df_31.to_excel(writer, sheet_name='quartiles_analysis_31')\n",
    "quartile_cutoffs_df_31.to_excel(writer, sheet_name='quartile_cutoffs_31')\n",
    "unique_list_31.to_excel(writer, sheet_name='unique_31')\n",
    "quartiles_df_31_teach.to_excel(writer, sheet_name='quartiles_analysis_31_teach')\n",
    "quartile_cutoffs_df_31_teach.to_excel(writer, sheet_name='quartile_cutoffs_31_teach')\n",
    "unique_list_31_teach.to_excel(writer, sheet_name='unique_31_teach')\n",
    "\n",
    "assumptions_list_32.to_excel(writer, sheet_name='slicing_assumptions_32')\n",
    "quartiles_df_32.to_excel(writer, sheet_name='quartiles_analysis_32')\n",
    "quartile_cutoffs_df_32.to_excel(writer, sheet_name='quartile_cutoffs_32')\n",
    "unique_list_32.to_excel(writer, sheet_name='unique_32')\n",
    "quartiles_df_32_teach.to_excel(writer, sheet_name='quartiles_analysis_32_teach')\n",
    "quartile_cutoffs_df_32_teach.to_excel(writer, sheet_name='quartile_cutoffs_32_teach')\n",
    "unique_list_32_teach.to_excel(writer, sheet_name='unique_32_teach')\n",
    "\n",
    "assumptions_list_33.to_excel(writer, sheet_name='slicing_assumptions_33')\n",
    "quartiles_df_33.to_excel(writer, sheet_name='quartiles_analysis_33')\n",
    "quartile_cutoffs_df_33.to_excel(writer, sheet_name='quartile_cutoffs_33')\n",
    "unique_list_33.to_excel(writer, sheet_name='unique_33')\n",
    "quartiles_df_33_teach.to_excel(writer, sheet_name='quartiles_analysis_33_teach')\n",
    "quartile_cutoffs_df_33_teach.to_excel(writer, sheet_name='quartile_cutoffs_33_teach')\n",
    "unique_list_33_teach.to_excel(writer, sheet_name='unique_33_teach')\n",
    "\n",
    "assumptions_list_34.to_excel(writer, sheet_name='slicing_assumptions_34')\n",
    "quartiles_df_34.to_excel(writer, sheet_name='quartiles_analysis_34')\n",
    "quartile_cutoffs_df_34.to_excel(writer, sheet_name='quartile_cutoffs_34')\n",
    "unique_list_34.to_excel(writer, sheet_name='unique_34')\n",
    "quartiles_df_34_teach.to_excel(writer, sheet_name='quartiles_analysis_34_teach')\n",
    "quartile_cutoffs_df_34_teach.to_excel(writer, sheet_name='quartile_cutoffs_34_teach')\n",
    "unique_list_34_teach.to_excel(writer, sheet_name='unique_34_teach')\n",
    "\n",
    "assumptions_list_35.to_excel(writer, sheet_name='slicing_assumptions_35')\n",
    "quartiles_df_35.to_excel(writer, sheet_name='quartiles_analysis_35')\n",
    "quartile_cutoffs_df_35.to_excel(writer, sheet_name='quartile_cutoffs_35')\n",
    "unique_list_35.to_excel(writer, sheet_name='unique_35')\n",
    "quartiles_df_35_teach.to_excel(writer, sheet_name='quartiles_analysis_35_teach')\n",
    "quartile_cutoffs_df_35_teach.to_excel(writer, sheet_name='quartile_cutoffs_35_teach')\n",
    "unique_list_35_teach.to_excel(writer, sheet_name='unique_35_teach')\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
